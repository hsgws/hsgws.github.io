---
title: "時系列分析 & 階層ベイズ"
date: "更新：`r Sys.time()`"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
    df_print: "paged"
    highlight: pygments
    # theme: lumen
    md_extensions: -ascii_identifiers
    css: "template/style_ch.css"
    includes:
      in_header: "template/head.html"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, fig.width = 10)
# packages
library(plotly)
library(broom)
# library(pander)
library(knitr)
library(tidyverse)
library(kableExtra)
```


## 1.分析例①：売上予測
### データ
**緑茶ペットボトルの日次販売本数データ（data_tea.csv）**

- オフィス街のコンビニでの販売データ
- 13週（91日）のデータを訓練期間11週（77日）と予測期間2週（14日間）に分割して，前半の訓練期間でパラメータを推定，後半の予測期間で予測力の検証を行う


```{r, echo=FALSE}
data_tea <- read.csv("data/data_tea.csv")
head(data_tea)
```

| 変数名  | 内容                                        |
| ------- | ------------------------------------------- |
| date    | 日付                                        |
| num     | 販売本数　$(y_t)$                           |
| day     | 曜日（1＝月曜，2＝火曜，…，7＝日曜）        |
| holiday | 祝日フラグ（1＝祝日，0＝それ以外）　$(x_t)$ |

**データ出典**：日経NEED POSデータ


```{r, echo=FALSE}
data_tea$date <- as.Date(data_tea$date)

data_tea %>% 
  ggplot(mapping = aes(x = date, y = num)) +
  geom_line() +
  scale_x_date(date_labels = "%m-%d", date_breaks = "1 weeks") +
  labs(title = "販売本数の日次グラフ")
```

### モデル
#### 観測モデル
$$
y_t = a_t + s_t + \beta x_t + \varepsilon_t; \qquad  \varepsilon_t \sim N(0, \sigma^2_y)
$$

#### システムモデル
$$
a_t = a_{t-1} + v_t; \qquad  v_t \sim N(0, \sigma^2_a) \\
s_t = -\sum_{j=1}^6 s_{t-j} + \delta_t; \qquad  \delta_t \sim N(0, \sigma^2_s)
$$

- $y_t$：販売本数
- $x_t$：祝日ダミー
- $a_t$：トレンド成分
- $s_t$：曜日周期成分
- $\beta$：祝日効果


### Rコード（推定）
```{r fig.show='hide', message=FALSE, warning=FALSE, results='hide'}
# パッケージのインストール（初回のみ実行）
# install.packages("KFAS")  # 状態空間モデルのパッケージ

# パッケージの読込み
library(KFAS)

# データの読み込み
data_tea <- read.csv("data/data_tea.csv")

# 訓練データと予測データへのデータ分割
train_data <- data_tea[1:77,] # 訓練データ（2015/04/01 ~ 2015/06/16，77日間）
test_data <- data_tea[78:91,] # 予測データ（2015/06/17 ~ 2015/06/30，14日間）

# 分析モデルの定義
model <- SSModel(
  num ~ SSMtrend(1, Q = NA) + SSMseasonal(7, sea.type = "dummy", Q = NA) + holiday,
  H = NA,
  data = train_data
)

# 分散パラメータの推定
fit <- fitSSM(model, inits = rep(0, 3))

# 分散パラメータの推定値
fit$model$H   # 観測モデルの誤差項の分散
fit$model$Q   # システムモデルの誤差項の分散

# 状態の推定（カルマンフィルタ，平滑化）
result <- KFS(fit$model)

# 状態の推定値
result$alphahat

# （参考）状態の推定値の図示
# install.packages("ggfortify") # 結果図示用のパッケージ，初回のみ実行
library(ggfortify)
autoplot(result$alphahat[, c("holiday" ,"level", "sea_dummy1")])
```


**`SSModel(formula, H, data)`：モデルの記述・作成**

- **`formula`**：目的変数・説明変数の指定
	- `SSMtrend(1, Q = NA)`：1次のトレンド項
	- `SSMseasonal(period, sea.type = "dummy", Q = NA)`：曜日周期項
	  - `period` はモデル化する周期 ⇒ 日次データであれば曜日周期で `period = 7`, 月次データであれば月周期で `period = 12`
	- `SSMregression(~ holiday, Q = 0)`：祝日フラグ
	- `Q = NA` ならシステムモデルの分散を推定（＝時変の係数），`Q = 0` なら分散を0に固定（＝時間不変の係数）
- **`H`**：観測モデルの分散
- **`data`**：観測データの指定


**`fitSSM(model, inits)`：パラメータの推定**

- **`model`**：`SSModel` で作成したモデルの指定
- **`inits`**：推定パラメータの初期値 ⇒ `SSModel` 内の `NA` の数だけ指定（`rep(0,3)` は0を3つ並べる関数）
- `fitSSM` 関数の出力のうちパラメータ推定値は `model`（上記例では `fit$model`）に保存されている。


**`KFS(model)`：状態のフィルタリング＆平滑化（カルマンフィルタ）**

- **`model`**：`fitSSM` で推定したモデルの指定
- `KFS` 関数の出力のうち平滑化状態の推定値は `alphahat`（上記例では `result$alphahat`）に保存されている。その他の出力は `KFS` のヘルプの `Value` を参照。


#### Rコードの出力
##### パラメータ推定値
```{r echo=FALSE}
fit$model$H   # 観測モデルの誤差項の分散
fit$model$Q   # システムモデルの誤差項の分散
```

システムモデルの誤差項の分散は対角成分の左上からトレンド成分 $a_t$ の分散 $Q_1$，曜日周期成分 $s_t$ の分散 $Q_2$


##### 状態の推定値（最初の10日分のみ表示）
```{r echo=FALSE}
result$alphahat %>% head(10)
```

- result.muhat：観測期間の売上予測値（当てはめ値） ⇒ level + sea_dummy1 + holiday * x
- holiday：祝日効果 $\beta$ の推定値
- level：トレンドの推定値
- sea_dummy1：曜日周期成分の推定値
- sea_dummy2 ~ 6：1～5日前までの曜日周期成分の推定値


##### （参考）状態の推定値の図示
```{r echo=FALSE}
autoplot(result$alphahat[, c("holiday" ,"level", "sea_dummy1")])
```

上から，祝日効果，トレンド，曜日周期


### Rコード（予測）
```{r message=FALSE, warning=FALSE, results='hide', fig.show='hide'}
# 予測用データの作成
newdata <- SSModel(
  rep(NA, 14) ~ SSMtrend(1, Q = NA) + SSMseasonal(7, sea.type = "dummy", Q = NA) + holiday,
  H = NA, 
  data = test_data
)

# fitSSM で推定したパラメータの代入
newdata$H <- fit$model$H    # 観測モデルの分散
newdata$Q <- fit$model$Q    # システムモデルの分散

# 予測の実行
pred <- predict(fit$model, n.ahead = 14, newdata = newdata, interval = "prediction", level = 0.95)

# 予測結果
pred

# 予測結果の評価
# install.packages("Metrics") # 評価指標計算用のパッケージ, 初回のみ実行
library(Metrics)
mape(test_data$num, pred[, "fit"])
rmse(test_data$num, pred[, "fit"])

# （参考）予測結果の図示
# install.packages("ggplot2") # 図示用のパッケージ, 初回のみ実行
library(ggplot2)
test_data <- cbind(test_data, pred)
test_data$date <- as.Date(test_data$date)

ggplot(test_data, mapping = aes(y = num, x = date)) +
  geom_line() +
  geom_line(aes(y = fit), colour = "red") +
  geom_line(aes(y = lwr), colour = "red", linetype = "dotted") +
  geom_line(aes(y = upr), colour = "red", linetype = "dotted") +
  scale_x_date(date_labels = "%m-%d", date_breaks = "1 days")
```

**`predict(model, n.ahead, newdata, interval, level)`：予測の実行**

- **`model`**：`fitSSM` で推定したモデル
- **`n.ahead`**：予測する期間数
- **`newdata`**：予測用の説明変数データ
	- 予測を行う際にも，予測用の説明変数（今回は祝日フラグ）が入った `SSModel` を作成する必要がある
	- 目的変数（販売本数）は，予測期間分（7日間）の欠損値 `rep(NA, 7)` を指定
	- 分散パラメータは `fitSSM` で推定したものを代入
	- 説明変数がないモデル（例えばトレンドと周期成分のみ）の場合は `newdata` は不要
- **`interval`**：予測の場合は `prediction` を指定
- **`level`**：予測（信頼）区間の指定


**`mape(actual, predicted)`, `rmse(actual, predicted)`：予測値の評価**

- **`actual`**：実績値
- **`predicted`**：予測値
  - KFASパッケージの `predict` 関数の出力の予測値は `pred[, "fit"]` で抜き出す。`pred$fit` では抜き出せないことに注意。

$MAPE = \frac{1}{n}\sum_{t=1}^n \left|\frac{y_t-\hat{y}}{y_t}\right|$：平均絶対誤差率  
$RMSE = \frac{1}{n}\sum_{t=1}^n \left(y_t-\hat{y}\right)^2$：平均二乗偏差


#### Rコードの出力
##### 予測結果
```{r echo=FALSE}
pred
```

##### 予測結果の評価
```{r echo=FALSE}
mape(test_data$num, pred[, "fit"])
rmse(test_data$num, pred[, "fit"])
```

##### （参考）予測結果の図示
```{r echo=FALSE}
ggplot(test_data, mapping = aes(y = num, x = date)) +
  geom_line() +
  geom_line(aes(y = fit), colour = "red") +
  geom_line(aes(y = lwr), colour = "red", linetype = "dotted") +
  geom_line(aes(y = upr), colour = "red", linetype = "dotted") +
  scale_x_date(date_labels = "%m-%d", date_breaks = "1 days")
```


### 説明変数を含まないモデル*
#### 観測モデル
$$
y_t = a_t + s_t + \varepsilon_t; \qquad  \varepsilon_t \sim N(0, \sigma^2_y)
$$

#### システムモデル
$$
a_t = a_{t-1} + v_t; \qquad  v_t \sim N(0, \sigma^2_a) \\
s_t = -\sum_{j=1}^6 s_{t-j} + \delta_t; \qquad  \delta_t \sim N(0, \sigma^2_s)
$$

#### Rコード
##### 推定
```{r fig.show='hide', message=FALSE, warning=FALSE, results='hide'}
# 分析モデルの定義
model_noholiday <- SSModel(
  num ~ SSMtrend(1, Q = NA) + SSMseasonal(7, sea.type = "dummy", Q = NA),
  H = NA,
  data = train_data
)

# パラメータ推定
fit_noholiday <- fitSSM(model_noholiday, inits = rep(0, 3))

# 状態のフィルタリング＆平滑化
result_noholiday <- KFS(fit_noholiday$model)

# パラメータ推定値
fit_noholiday$model$H   # 観測モデルの誤差項の分散
fit_noholiday$model$Q   # システムモデルの誤差項の分散

# 平滑化状態の推定値
result_noholiday$alphahat

# 平滑化状態の図示
autoplot(result_noholiday$alphahat[, c("level", "sea_dummy1")])
```

##### 予測
```{r fig.show='hide', message=FALSE, warning=FALSE, results='hide'}
# 予測の実行
# 説明変数を含まないモデルは予測用データの作成は不要
pred_noholiday <- predict(fit_noholiday$model, n.ahead = 14, interval = "prediction", level = 0.95)

# 予測結果
pred_noholiday

# 予測結果の評価
mape(test_data$num, pred_noholiday[, "fit"])
rmse(test_data$num, pred_noholiday[, "fit"])
```

#### Rコードの出力
##### パラメータ推定値
```{r echo=FALSE}
fit_noholiday$model$H   # 観測モデルの誤差項の分散
fit_noholiday$model$Q   # システムモデルの誤差項の分散
```

##### 予測結果
```{r echo=FALSE}
pred_noholiday
```

##### 予測結果の評価
```{r echo=FALSE}
mape(test_data$num, pred_noholiday[, "fit"])
rmse(test_data$num, pred_noholiday[, "fit"])
```

- 説明変数（祝日ダミー）の有無で予測力を比較すると，MAPEでは 0.102（あり）vs. 0.094（なし），RMSEでは  23.7（あり）vs. 24.5（なし）と，2つの指標で評価が分かれる
  - RMSEは実績値から大きく離れた予測値を重視して評価する（＝実績値から大きく離れるほど罰則が大きくなる）ので，予測が大きく外れないことを重視する場合は RMSE が良いモデルを採択した方がよい
- 誤差項の分散の推定値は「説明変数あり」モデルの方が小さいため，予測値の95％区間は「説明変数あり」モデルの方が狭くなる ⇒ 両モデルの予測結果の出力を比較せよ


## 2.分析例②：時変回帰係数*
### データ
**醤油の日次販売個数データ**（sec8_DLM.csv）
```{r, echo=FALSE}
sec8_DLM <- read.csv("data/sec8_DLM.csv")
head(sec8_DLM)
```

| 変数名          | 内容                                                         |
| --------------- | ------------------------------------------------------------ |
| Date            | 日付（2000/01/02 ~ 2003/09/05，1314日間）                    |
| LogPI_A         | 商品Aの点数PI（来店客1000人当たり販売点数）の対数値　$(y_t)$ |
| LogPriceIndex_A | 商品Aの価格掛率の対数値　$(x_{1t})$                          |
| LogPriceIndex_B | 商品Bの価格掛率の対数値　$(x_{2t})$                          |
| Display_A       | 商品Aの山積み陳列実施の有無　$(x_{3t})$                      |
| Display_B       | 商品Bの山積み陳列実施の有無　$(x_{4t})$                      |

**データ出典**：佐藤 (2016) 『マーケティングの統計モデル』朝倉書店（8章）


```{r, echo=FALSE}
# plot.ts(sec8_DLM$LogPI_A, ylab = "LogPI_A", main = "Time series plot")

sec8_DLM$Date <- as.Date(as.character(sec8_DLM$Date),"%Y%m%d")
sec8_DLM %>% 
  ggplot(mapping = aes(x = Date, y = LogPI_A)) +
  geom_line() +
  scale_x_date(date_labels = "%Y-%m-%d", date_breaks = "6 months") +
  labs(title = "商品Aの点数PIの日次グラフ")
```

### モデル
#### 観測モデル
$$
y_t = a_t + \sum_{j=1}^4 \beta_{j,t} x_{j,t} + \varepsilon_t; \qquad  \varepsilon_t \sim N(0, \sigma^2_y)
$$

#### システムモデル
$$
a_t = a_{t-1} + v_t; \qquad  v_t \sim N(0, \sigma^2_a) \\
\beta_{j,t} = \beta_{j,t-1} + \eta_{j,t}; \qquad  \eta_{j,t} \sim N(0, \sigma^2_{\beta_j})
$$

### Rコード
```{r, results='hide', message=FALSE, fig.keep='none'}
# パッケージの読込み
library(KFAS)
library(ggfortify)

# データの読み込み
sec8_DLM <- read.csv("data/sec8_DLM.csv")

# 分析モデルの定義
model <- SSModel(
  LogPI_A ~ SSMtrend(1, Q = NA) + 
    SSMregression(~ LogPriceIndex_A + LogPriceIndex_B + Display_A + Display_B, Q = diag(NA, 4)),
  H = NA,
  data = sec8_DLM
)

# 分散パラメータの推定
fit <- fitSSM(model, inits = rep(0,6))

# 分散パラメータの推定値
fit$model$H   # 観測モデルの誤差項の分散
fit$model$Q   # システムモデルの誤差項の分散

# 状態（時変係数）の推定（カルマンフィルタ，平滑化）
result <- KFS(fit$model)

# 状態の推定値
result$alphahat

# 状態の推定値の図示
autoplot(result$alphahat)
```

時変係数を推定する場合は，`SSModel` 関数の引数に `SSMregression` を追加し，`Q = diag(NA, 4)` で回帰係数の分散を推定パラメータとして指定する。
詳細は下記参考文献を参照。

1. [馬場（2018）『時系列分析と状態空間モデルの基礎』プレアデス出版](https://logics-of-blue.com/tsa-ssm-book-support/)
2. [佐藤（2015）『マーケティングの統計モデル』朝倉書店，第8章](https://www.asakura.co.jp/detail.php?book_code=12853)
3. [野村（2016）『カルマンフィルタ（統計学 One Point）』共立出版](https://www.kyoritsu-pub.co.jp/book/b10003774.html)


#### Rコードの出力
##### パラメータ推定値
```{r echo=FALSE}
fit$model$H   # 観測モデルの誤差項の分散
fit$model$Q   # システムモデルの誤差項の分散
```

##### 状態の推定値
```{r echo=FALSE}
head(result$alphahat, 10)
```

##### 状態の推定値の図示
```{r echo=FALSE}
autoplot(result$alphahat)
```


## 3.分析例③：階層ベイズ多項ロジット*
### データ
**醤油のID付POSデータ**（sec8_data1.csv）
```{r, echo=FALSE}
sec8_data1 <- read.csv("data/sec8_data1.csv")
head(sec8_data1)
```

| 変数名       | 内容                          |
| ------------ | ----------------------------- |
| PNL          | 消費者パネルID                |
| Date         | 購買日                        |
| Product1 ~ 3 | 購買の有無（0＝非購買，1＝購買） |
| Choice       | 購買ブランド（1,2,3） ⇒ 以降ではA,B,C表記                  |
| Price1 ~ 3   | 価格掛率（定価＝1）                     |
| Disp1 ~ 3    | 山積み陳列実施の有無（1＝実施，0＝非実施）         |
| Ad1 ~ 3      | チラシ掲載の有無（1＝実施，0＝非実施）              |


**消費者属性データ**（sec8_data2.csv）
```{r, echo=FALSE}
sec8_data2 <- read.csv("data/sec8_data2.csv")
head(sec8_data2)
```

| 変数名 | 内容           |
| ------ | -------------- |
| PNL    | 消費者パネルID |
| age    | 年齢           |
| family | 家族人数       |


**データ出典**：佐藤 (2016) 『マーケティングの統計モデル』朝倉書店（8章）

- sec8_data1.csv は1家計（パネル）の複数購買機会でのブランド選択が記録されたID付POSデータ（または消費者パネルデータとも呼ばれる）
- sec8_data1.csv と sec8_data2.csv の消費者パネルID（PNL）は対応している
- 分析のためには sec8_data1.csv を消費者ごとの list 形式に加工する必要があるが，加工方法が特殊なため加工済みのデータ（yxdata.RData）を用意した

### モデル
#### 効用関数（個体内モデル）
$$
\begin{align}
U_{hA} &= \beta_{hA} + \beta_1 \text{Price}_{hA} + \beta_2 \text{Display}_{hA} + \beta_3 \text{Ad}_{hA} + \varepsilon_{hA} \\
U_{hB} &= \beta_{hB} + \beta_1 \text{Price}_{hB} + \beta_2 \text{Display}_{hB} + \beta_3 \text{Ad}_{hB} + \varepsilon_{hB} \\
U_{hC} &= 0 + \beta_1 \text{Price}_{hC} + \beta_2 \text{Display}_{hC} + \beta_3 \text{Ad}_{hC} + \varepsilon_{hC}
\end{align}
$$

#### 階層モデル
$$
  \beta_{hj} = \Delta_{j1} \text{age}_h + \Delta_{j2} \text{family}_h + u_{hj} \qquad (j = A, B, 1, 2, 3)
$$

以下のRコードで利用する `bayesm` パッケージの `rhierMnlRwMixture` 関数では，階層モデルの説明変数は平均を0に基準化する必要がある

### Rコード
```{r, results='hide', message=FALSE, fig.keep='none'}
# パッケージのインストール（初回のみ実行）
# install.packages("bayesm")  # ベイズ推定のパッケージ

# パッケージの読込み
library(bayesm)

# データの読み込み
sec8_data1 <- read.csv("data/sec8_data1.csv")
sec8_data2 <- read.csv("data/sec8_data2.csv")

id <- sec8_data2$PNL  # 消費者パネルIDの抽出
H <- 103  # 消費者パネル数
J <- 3    # ブランド数
K <- 3    # マーケティング変数の数 (Prie, Disp Ad)

# 加工済みの yxdata (list 形式の消費者パネル別選択データ) の読み込み
load("data/yxdata.RData")

# 属性データの基準化（平均のみ）
zdata <- scale(sec8_data2[,c("age", "family")], scale = FALSE)

# rhierMnlRwMixture コマンドでの分析のためにデータを list 形式に変換
dataset <- list(lgtdata = yxdata, Z = zdata, p = J)

# lgtdata : list 形式の消費者行動データ
# Z : 消費者の属性データ
# p : ブランド数

# MCMCの設定
set.seed(1)  # 乱数の初期値
mcmc <- list(R = 3000) # MCMCのサンプル数
prior <- list(ncomp = 1)  # 事前分布の設定 ⇒ 初期設定の散漫な事前分布

# MCMCの実行
out <- rhierMnlRwMixture(Data = dataset, Prior = prior, Mcmc = mcmc)

# パネル毎の係数 beta の推定値（出力省略）
R <- 3000
beta_all <- apply(out$betadraw[,,(0.1*R):R], 1, rowMeans)
# print(beta_all)

# パネル毎の係数 beta の推定値プロット
plot(out$betadraw)

# 係数 Delta の推定値と出力整形
summary_Delta <- summary(out$Deltadraw, QUANTILES = FALSE)
Delta_mean <- matrix(summary_Delta[,1], nrow =5, byrow = TRUE)
Delta_sd <- matrix(summary_Delta[,2], nrow =5, byrow = TRUE)

rownames(Delta_mean) <- c("Brand.1", "Brand.2", "Price", "Disp", "Ad")
colnames(Delta_mean) <- c("age", "family")
rownames(Delta_sd) <- c("Brand.1", "Brand.2", "Price", "Disp", "Ad")
colnames(Delta_sd) <- c("age", "family")

print(Delta_mean)
print(Delta_sd)
```

<br />
<details><summary>yxdata（list 形式の消費者パネル別選択データ）の作成プログラム（クリックで表示）</summary><div>
```{r, eval=FALSE}
# 消費者パネルデータ (sec8_data1) を消費者パネル毎の list 形式データに変換
yxdata <- list()
for (h in 1:H) {
  data_h <- subset(sec8_data1, PNL == id[h])
  ydata_h <- data_h$Choice
  xdata_h <- createX(p = J, na = K, nd = NULL, Xa = data_h[,7:15], Xd = NULL, base = 3)
  yxdata[[h]] <- list(id = id[h], y = ydata_h, X = xdata_h)
}
```
</div></details>
<br />

#### Rコードの出力
##### パネル毎の係数 $\beta_h$ の推定値プロット
```{r echo=FALSE}
plot(out$betadraw)
```

##### 係数 $\Delta$ の推定値
上：Delta_mean（事後平均），下：Delta_sd（事後標準偏差）
```{r, echo=FALSE}
print(Delta_mean)
print(Delta_sd)
```

### 推定結果
```{r echo=FALSE}
cbind(Delta_mean[, 1], Delta_sd[, 1], Delta_mean[, 2], Delta_sd[, 2]) %>% 
  kable(digits = 3, col.names = c("事後平均", "事後標準偏差", "事後平均", "事後標準偏差")) %>% 
  add_header_above(c(" " = 1, "age" = 2, "family" = 2)) %>% 
  kable_styling()
```

- 90%有意水準で判断すると，「Disp × age (-0.574)」 と 「Brand.2 × family (0.050)」が有意
- 年齢が高いほど山積み陳列に反応しにくく，家族人数が多いほどブランドBの選好度が高い
⇒ 価格とチラシが有意でないことを含め，年齢が高い消費者ほど購買ブランドが固定化している可能性がある
<br />

分析例で利用した `bayesm` パッケージについては下記参考文献の 1 を参照。
ただし，Rでベイズ推定を行う場合，現在は stan の利用が標準的な方法になっている。stan については参考文献2，3などを参照。

1. [Rossi et al. (2005) "Bayesian Statistics and Marketing," Wiley](https://onlinelibrary.wiley.com/doi/book/10.1002/0470863692) ⇒ [図書館電子ブックリンク](https://ebookcentral.proquest.com/lib/hosei/detail.action?docID=792774)
2. [松浦 (2016) 『StanとRでベイズ統計モデリング（Wonderful R）』共立出版](https://www.kyoritsu-pub.co.jp/book/b10003786.html) ⇒ [図書館電子ブックリンク](https://kinoden.kinokuniya.co.jp/hosei_u/bookdetail/p/KP00036432)
3. [馬場 (2019) 『RとStanではじめるベイズ統計モデリングによるデータ分析入門』講談社](https://www.kspub.co.jp/book/detail/5165362.html)


## 4.データ分析実習
### データ
**北海道の月次宿泊者数データ** (hokkaido.csv) 

- データ観測期間は2011年1月～2020年12月の120ヶ月
- 2020年以降のデータは新型コロナの影響で市場環境が大きく変わっているため，2011年1月～2017年12月（84ヶ月）を訓練期間，2018年1月～2019年12月（24ヶ月）を予測期間として分析を行う

```{r, echo=FALSE}
hokkaido <- read.csv("data/hokkaido.csv")
head(hokkaido)
```


| 変数名 | 内容           |
| ------ | -------------- |
| date   | 日付（年-月） |
| num    | 宿泊者数 （単位・千人）      |
| leap    | うるう月ダミー       |
| holiday    | 休日数（土日・祝日）       |

**データ出典**：[宿泊旅行統計調査（観光庁）](https://www.mlit.go.jp/kankocho/siryou/toukei/shukuhakutoukei.html)


```{r, echo=FALSE}
library(lubridate)

hokkaido %>% 
  mutate(date = ym(date)) %>% 
  ggplot(mapping = aes(x = date, y = num)) +
  geom_line() +
  scale_x_date(date_labels = "%y-%m", date_breaks = "6 months") +
  labs(title = "北海道の月次宿泊者数データ") +
  ylab(label = "宿泊者数（単位：千人）")
```


### 課題
1. データを訓練期間（2011年1月～2017年12月，84ヶ月）と予測期間（2018年1月～2019年12月，24ヶ月）に分割せよ
2. 訓練期間データで以下の2つの状態空間モデルを推定せよ
3. 2つのモデルで24ヶ月先までの予測を行い，どちらのモデルの予測精度が高いか予測期間データのMAPEとRMSEで比較せよ

##### **モデル1**
宿泊者数 ＝ トレンド ＋ 12ヶ月周期 ＋ うるう月

##### **モデル2**
宿泊者数 ＝ トレンド ＋ 12ヶ月周期 ＋ うるう月 ＋ 休日数


- 訓練期間：2011年1月～2017年12月（84ヶ月）⇒ データの1～84行目
- 予測期間：2018年1月～2019年12月（24ヶ月）⇒ データの85～108行目

<br />
<details><summary>Rコード（クリックで表示）</summary><div>
```{r, eval=FALSE}
# パッケージの読み込み
library(KFAS)
library(Metrics)

# データの読み込み
hokkaido <- read.csv("data/hokkaido.csv")

# 訓練・予測期間の分割
train_data <- hokkaido[1:84,]
test_data <- hokkaido[85:108,]

# モデル1
## モデル定義
model1 <- SSModel(
  num ~ SSMtrend(1, Q = NA) + SSMseasonal(12, sea.type = "dummy", Q = NA) + leap,
  H = NA,
  data = train_data
)

## 推定
fit1 <- fitSSM(model1, inits = rep(0, 3))
result1 <- KFS(fit1$model)

## 予測
newdata1 <- SSModel(
  rep(NA, 24) ~ SSMtrend(1, Q = NA) + SSMseasonal(12, sea.type = "dummy", Q = NA) + leap,
  H = NA, 
  data = test_data
)

newdata1$H <- fit1$model$H
newdata1$Q <- fit1$model$Q

pred1 <- predict(fit1$model, n.ahead = 24, newdata = newdata1, interval = "prediction", level = 0.95)

# モデル2
## モデル定義
model2 <- SSModel(
  num ~ SSMtrend(1, Q = NA) + SSMseasonal(12, sea.type = "dummy", Q = NA) + leap + holiday,
  H = NA,
  data = train_data
)

## 推定
fit2 <- fitSSM(model2, inits = rep(0, 3))
result2 <- KFS(fit2$model)

## 予測
newdata2 <- SSModel(
  rep(NA, 24) ~ SSMtrend(1, Q = NA) + SSMseasonal(12, sea.type = "dummy", Q = NA) + leap + holiday,
  H = NA,
  data = test_data
)

newdata2$H <- fit2$model$H
newdata2$Q <- fit2$model$Q

pred2 <- predict(fit2$model, n.ahead = 24, newdata = newdata2, interval = "prediction", level = 0.95)

# モデル比較
rmse(test_data$num, pred1[, "fit"])
rmse(test_data$num, pred2[, "fit"])

mape(test_data$num, pred1[, "fit"])
mape(test_data$num, pred2[, "fit"])

# 平滑化状態の図示（モデル1）
library(ggfortify)
autoplot(result1$alphahat[, c("leap" ,"level", "sea_dummy1")])

# （参考）予測期間の実績値と予測値の図示（モデル1）
test_data <- cbind(test_data, pred1)

library(lubridate)  # 要 lubridate パッケージのインストール
test_data$date <- ym(test_data$date) # date列（「年-月」表記）をDate形式へ変更

ggplot(test_data, mapping = aes(y = num, x = date)) +
  geom_line() +
  geom_line(aes(y = fit), colour = "red") +
  geom_line(aes(y = lwr), colour = "red", linetype = "dotted") +
  geom_line(aes(y = upr), colour = "red", linetype = "dotted") +
  scale_x_date(date_labels = "%Y-%m", date_breaks = "2 months")
```
</div></details>


<!-- ```{r} -->
<!-- df <- hokkaido -->
<!-- df$num[85:120] <- NA -->

<!-- library(lubridate) -->
<!-- df %>% -->
<!--   mutate(date = ym(date)) %>% -->
<!--   ggplot(mapping = aes(x = date, y = num)) + -->
<!--   geom_line() + -->
<!--   scale_x_date(date_labels = "%y-%m", date_breaks = "6 months") + -->
<!--   labs(title = "北海道の月次宿泊者数データ") + -->
<!--   ylab(label = "宿泊者数（単位：千人）") -->


<!-- df <- df %>%  -->
<!--   filter(!is.na(num)) %>%  -->
<!--   mutate(num_dif = c(NA, diff(num))) %>%  -->
<!--   mutate(num_dif2 = c(rep(NA, 12), diff(num_dif, lag = 12))) -->

<!-- df %>% -->
<!--   mutate(date = ym(date)) %>% -->
<!--   ggplot(mapping = aes(x = date, y = num)) + -->
<!--   geom_line() + -->
<!--   scale_x_date(date_labels = "%y-%m", date_breaks = "6 months") + -->
<!--   labs(title = "北海道の月次宿泊者数データ") + -->
<!--   ylab(label = "宿泊者数（単位：千人）") -->

<!-- df %>% -->
<!--   mutate(date = ym(date)) %>% -->
<!--   ggplot(mapping = aes(x = date, y = num_dif)) + -->
<!--   geom_line() + -->
<!--   scale_x_date(date_labels = "%y-%m", date_breaks = "6 months") + -->
<!--   labs(title = "北海道の月次宿泊者数データ") + -->
<!--   ylab(label = "宿泊者数（単位：千人）") -->

<!-- df %>% -->
<!--   mutate(date = ym(date)) %>% -->
<!--   ggplot(mapping = aes(x = date, y = num_dif2)) + -->
<!--   geom_line() + -->
<!--   scale_x_date(date_labels = "%y-%m", date_breaks = "6 months") + -->
<!--   labs(title = "北海道の月次宿泊者数データ") + -->
<!--   ylab(label = "宿泊者数（単位：千人）") -->

<!-- ``` -->

