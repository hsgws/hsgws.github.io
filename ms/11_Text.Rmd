---
title: "テキスト分析"
date: "更新：`r format(Sys.time(), '%Y/%m/%d')`"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
    df_print: "paged"
    highlight: pygments
    # theme: lumen
    md_extensions: -ascii_identifiers
    css: "template/style_ch.css"
    includes:
      in_header: "template/head.html"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, fig.width = 10)
# packages
library(plotly)
library(broom)
# library(pander)
library(knitr)
library(tidyverse)
library(magrittr)
```



```{r eval=FALSE, include=FALSE}
if(0) {
  amzn <- read_csv("data/amazon_tablet_review.csv")
  
  amzn %>% 
    group_by(star) %>% 
    summarise(n = n())
  
  for (i in 1:5) {
    tmp <- amzn %>% 
      filter(star == i) %>% 
      select(review)
    write.table(tmp, file = paste0("data/tablet/S", i, ".txt"), row.names = FALSE, col.names = FALSE)
  }
}
```


## Rでの日本語テキストの分析

以下の分析例では形態素解析後の加工済みのデータを使って分析を行う。

Rでの形態素解析は，PCにMeCabをインストールし，RでRMeCabパッケージを利用することで実行できる。
MeCabのインストール方法は参考URLなどを参照。

##### MeCab インストール時の注意点
- R はバージョン 4.2 からデフォルトの文字コードが UTF-8 となったため，MeCab と RMeCab パッケージのインスト－ルには注意が必要（詳細は下記参考URLを参照）
- Windows のメモ帳や Excel の CSV で日本語を含むテキストデータファイルを作成する場合は，データを保存する際に文字コードを UTF-8 に指定して保存すること
- その他文字コード（主に Shift JIS）で保存されたデータは，R でデータを読み込む際に文字コードを指定すれば文字化けせずに読み込める

##### 参考URL
- RMeCab パッケージ：[GitHub - IshidaMotohiro/RMeCab: Interface to MeCab](https://github.com/IshidaMotohiro/RMeCab)
- MeCab のインストール：[アールメカブ | R+Linux+Python+CPP](https://rmecab.jp/new/)

##### データ加工・前処理に関する参考文献
- [村松（2021）『改訂2版 Rユーザのための RStudio［実践］入門』技術評論社](https://gihyo.jp/book/2021/978-4-297-12170-9)
- [本橋（2018）『前処理大全』技術評論社](https://gihyo.jp/book/2018/978-4-7741-9647-3)


## 1. 分析例①：対応分析

### データ
**沖縄県観光客の自由記述アンケート（data_okinawa.csv）**

```{r, echo=FALSE}
read.csv("data/data_okinawa.csv", row.names = 1) %>% 
  head()
```

- 総単語数（行数）：72単語
- 列名の "F" は女性，"M" は男性，"20～70" は年齢層を表す


**データ出典** ：[石田（2017）『Rによるテキストマイニング入門(第2版)』森北出版株式会社](https://www.morikita.co.jp/books/mid/084842)

<br />
<details><summary>データ前処理のRコード（クリックで表示）</summary><div>
```{r eval=FALSE}
library(tidyverse)
library(magrittr)
library(RMeCab)

mecab_out <- docDF("data/okinawa", type = 1, pos = c("名詞", "動詞", "形容詞"))

df <- mecab_out %>% 
  set_colnames(str_remove(colnames(.), ".txt")) %>% # 列名の ".txt" を除外
  filter(POS2 %in% c("一般", "固有", "自立")) %>%   # 分析対象単語の抽出
  filter(! TERM %in% c("ある", "いう", "いる", "する" ,"できる", "なる", "思う")) %>%  # ストップワードの削除 
  mutate(sum = select(., F20:M70) %>% rowSums()) %>% # 頻出数7未満の単語の削除
  filter(sum >= 7) %>% 
  select(-c(POS1:POS2, sum))

write_excel_csv(df, "data/data_okinawa.csv")
```
</div></details>


### Rコード

```{r results='hold', fig.show='hide'}
# パッケージのインストール（初回のみ実行）
# install.packages("FactoMineR") 
# install.packages("factoextra")

library(FactoMineR) 

# データの読み込み
okinawa <- read.csv("data/data_okinawa.csv", row.names = 1) # row.names = 1 でデータ内の1列目の単語を行名に指定

# 対応分析
result <- CA(okinawa)

# マップ上の単語数を減らした図の作成
library(factoextra)
fviz_ca_biplot(result, select.row = list(contrib = 60)) # 単語数を60個に削減
```


**`CA(X)`：対応分析**

- **`X`**：データまたはクロス集計表


**`fviz_ca_biplot(X, select.row)`：作図を拡張するための関数**

- **`X`**：`CA` 関数の出力
- **`select.row`**：表示する単語数の指定（`contrib`で影響度の高い順版で単語を指定）


#### Rコードの出力
##### FactoMineR パッケージ
```{r echo=FALSE}
result <- CA(okinawa)
```

右下の "Plots" に出力された図は "Zoom" から拡大，"Export" から保存が可能


##### factoextra パッケージ
```{r echo=FALSE}
result <- CA(okinawa, graph = FALSE)
fviz_ca_biplot(result, select.row = list(contrib = 60))
```


## 2. 分析例②：トピックモデル*

### データ
**プロテインSAVASのレビュー（data_savas.csv）**

```{r, echo=FALSE}
read.csv("data/data_savas.csv", row.names = 1) %>% 
  head()
```

- 総単語数（行数）：156単語
- レビュー数（列数）：190件

**データ出典** ：Amazonのレビューページ

<br />
<details><summary>データ前処理のRコード（クリックで表示）</summary><div>
```{r eval=FALSE}
library(tidyverse)
library(magrittr)
library(RMeCab)

review <- read.csv("data/review_savas.csv")
doc <- docDF(review, "text", type = 1, pos = c("名詞", "形容詞"), minFreq = 3)

data_savas <- doc %>% 
  # 記号の削除
  filter(!str_detect(TERM, "[:punct:]")) %>% 
  # 分析対象の品詞中分類
  filter(POS2 %in% c("一般", "固有名詞", "自立", "サ変接続", "形容動詞語幹", "副詞可能")) %>% 
  # アルファベットの大文字を小文字へ変換
  mutate(TERM = tolower(TERM)) %>%  
  # 重複単語行の統合
  select(-c(POS1:POS2)) %>%   
  group_by(TERM) %>% 
  summarise_all(list(sum)) %>% 
  column_to_rownames("TERM") %>%
  # 前処理後に単語数がゼロとなった列を削除
  select(which(colSums(.) > 0))

colnames(data_savas) <- paste0("review", review$id)

data_savas %>% 
  rownames_to_column(var = "TERM") %>% 
  write_excel_csv(file = "data/data_savas.csv")
```
</div></details>


### Rコード
```{r results='hide'}
# パッケージの読み込み（要インストール）
library(tm)
library(topicmodels)

# データの読み込み＆分析用に変換
data_savas <- read.csv("data/data_savas.csv", row.names = 1)
lda_data <- as.DocumentTermMatrix(t(data_savas), weighting = weightTf)

# LDAの実行
set.seed(1) # 推定用の乱数初期値の固定
result <- LDA(lda_data, k = 5, control = list(seed = 1))

# 各トピックの確率上位15単語
terms(result, 15)

# 各レビューのトピック分布
posterior(result)$topic

# 文章全体のトピック構成比
prop.table(table(topics(result)))
```


**`as.DocumentTermMatrix(x, weighting)`：LDA パッケージ用にデータを変換**

- **`x`**：単語の BOW データ
- **`weighting`**：重みの指定 ⇒ LDA の場合は `weightTf`

**`LDA(x, k, control)`：トピックモデルの推定**

- **`x`**：`as.DocumentTermMatrix` で変換したデータ
- **`k`**：トピック数
- **`control`**：オプション
  - 推定には乱数を使うため，実行のたびに少し異なる分析結果が出力される。同じ出力を得るためには，`seed` の設定で乱数を固定する。


#### Rコードの出力
##### 各トピックの確率上位15単語
```{r echo=FALSE}
terms(result, 15)
```

各トピックの解釈

1. 飲み方
2. 筋トレ
3. 味＆効果
4. タンパク質のコスパ
5. 味＆価格


##### 各レビューのトピック分布（最初の10件のみ表示）
```{r echo=FALSE}
posterior(result)$topic %>% 
  head(10)
```

##### 文章全体のトピック構成比
```{r echo=FALSE}
prop.table(table(topics(result)))
```


<!-- ```{r echo=FALSE} -->
<!-- review <- read.csv("data/review_savas.csv") -->
<!-- print(review[c(1, 3, 5), ]) -->
<!-- ``` -->


## 3. 分析例③：共起ネットワーク*

### データ
**沖縄県観光客の自由記述アンケート（data_okinawa2.csv）**
```{r, echo=FALSE}
read.csv("data/data_okinawa2.csv") %>% 
  head()
```

| 変数名      | 内容                    |
| ---------   | ------------------------- |
| N1          | 連続する2つの単語の第1単語       | 
| N2          | 連続する2つの単語の第2単語       | 
| freq        | 出現数（4回以上出現した単語の組み合わせ）        | 

- 分析例①と同じデータ
- ただし性別・年齢層の違いは無視して自由記述回答全体を使って単語の共起関係を抽出した

**データ出典** ：[石田（2017）『Rによるテキストマイニング入門(第2版)』森北出版株式会社](https://www.morikita.co.jp/books/mid/084842)

<br />
<details><summary>データ前処理のRコード（クリックで表示）</summary><div>
```{r eval=FALSE}
library(tidyverse)
library(magrittr)
library(RMeCab)

mecab_out <- docDF("data/okinawa", type = 1, pos = c("名詞", "動詞", "形容詞"),
                   N = 2, nDF = TRUE)

df <- mecab_out %>% 
  filter(! N1 %in% c("ある", "いう", "いる", "する" ,"できる", "なる", "思う")) %>% 
  filter(! N2 %in% c("ある", "いう", "いる", "する" ,"できる", "なる", "思う")) %>% 
  mutate(freq = select(., -c(N1:POS2)) %>% rowSums()) %>% 
  filter(freq > 3) %>% 
  select(c(N1:N2, freq))

write_excel_csv(df, "data/data_okinawa2.csv")
```
</div></details>

### Rコード
```{r fig.show='hide'}
# パッケージの読み込み（要インストール）
library(igraph)

# データの読み込み
data_okinawa2 <- read.csv("data/data_okinawa2.csv")

# 共起ネットワーク図の作成
graph_df <- graph_from_data_frame(data_okinawa2)
plot(graph_df, vertex.label = V(graph_df)$name)
```

#### Rコードの出力
```{r echo=FALSE}
plot(graph_df, vertex.label = V(graph_df)$name)
```

本ページ上では出力図の文字が小さくて分かりづらいが，R上では Zoom をクリックすることで出力図を拡大表示できる。



## 4. データ分析実習

### データ
**スマートウォッチ8製品のAmazonレビュー（data_smartwatch.csv）**

```{r, echo=FALSE}
read.csv("data/data_smartwatch.csv", row.names = 1) %>% 
  head()
```


| 列名  | 製品名                    | データ出典（レビューのURL）                       |
| --------- | ------------------------- | ---------------------------------------------------- |
| Apple8    | Apple Watch Series 8      | https://www.amazon.co.jp/dp/B0BDHWX8ZQ/ |
| AppleSE   | Apple Watch SE（第2世代） | https://www.amazon.co.jp/dp/B0BDJLWN1N/ |
| FitbitC5  | Fitbit Charge 5           | https://www.amazon.co.jp/dp/B09CSX5G3V/ |
| GarminFA  | GARMIN ForeAthlete 55     | https://www.amazon.co.jp/dp/B096KJL2DS/ |
| HuaweiB7  | HUAWEI Band 7             | https://www.amazon.co.jp/dp/B09YRV54M4/ |
| HuaweiGT3 | HUAWEI WATCH GT 3         | https://www.amazon.co.jp/dp/B09KV7L86G/ |
| Pixel     | Google Pixel Watch        | https://www.amazon.co.jp/dp/B0BGXH42B7/ |
| XiaomiB7  | Xiaomi Smart Band 7       | https://www.amazon.co.jp/dp/B0B3GP8B31/ |

- 各製品のレビューの「トップレビュー」順で30件ずつレビューを取得（取得日2022年12月）
- 画像のみのレビューは除外
- 総単語数（行数）：146単語


<br />
<details><summary>データ前処理のRコード（クリックで表示）</summary><div>
```{r eval=FALSE}
library(tidyverse)
library(magrittr)
library(RMeCab)

# 形態素解析
mecab_out <- docDF("data/smart_watch", type = 1, pos = c("名詞", "動詞", "形容詞"))

# 分析用データの作成
df <- mecab_out %>% 
  set_colnames(str_remove(colnames(.), ".csv")) %>% 	  # 列名の ".txt" を除外
  filter(POS2 %in% c("一般", "固有名詞", "自立")) %>%	  # 分析対象単語の抽出
  filter(! TERM %in% c("ある", "いう", "いる", "する" ,"できる", "なる", "思う")) %>% 	# ストップワードの削除
  mutate(TERM = tolower(TERM)) %>% 	# アルファベットの大文字を小文字へ変換
  select(-c(POS1:POS2)) %>% 	# 重複単語行の統合
  group_by(TERM) %>% 
  summarise_all(list(sum)) %>% 
  mutate(sum = select(., -c(TERM)) %>% rowSums()) %>% 	# 頻出数7未満の単語の削除
  filter(sum >= 7) %>% 
  select(-c(sum)) 

write_excel_csv(df, "data/data_smartwatch.csv")
```
</div></details>


### 課題
スマートウォッチ8製品のレビューデータで対応分析を実行し，結果を解釈せよ。

<br />
<details><summary>対応分析 Rコード（クリックで表示）</summary><div>
```{r fig.show='hide', eval=FALSE}
library(FactoMineR)

data_smartwatch <- read.csv("data/data_smartwatch.csv", row.names = 1)
result <- CA(data_smartwatch)

library(factoextra)
fviz_ca_biplot(result, select.row = list(contrib = 80)) # マップ上の単語を80個に削減
```
</div></details>